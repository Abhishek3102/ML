{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Advanced Big Mart Sales Analysis\n",
                "\n",
                "This notebook explores deeper insights and trends in the Big Mart Sales dataset, going beyond standardized preprocessing to look at interactions, distributions, and fine-grained performance metrics."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "# Set Style\n",
                "sns.set_style('whitegrid')\n",
                "plt.rcParams['figure.figsize'] = (12, 6)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Data Loading & Feature Engineering"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pd.read_csv('updated_dataset.csv')\n",
                "\n",
                "# Calculate Outlet Age if not present (Assuming data is from 2013 context)\n",
                "if 'Outlet_Age' not in df.columns:\n",
                "    df['Outlet_Age'] = 2013 - df['Outlet_Establishment_Year']\n",
                "\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Multivariate Analysis: MRP vs Sales vs Outlet Type\n",
                "**Insight Goal:** Do higher MRP items sell better in specific types of outlets (e.g., Supermarkets vs Grocery Stores)?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(15, 8))\n",
                "sns.scatterplot(data=df, x='Item_MRP', y='Item_Outlet_Sales', hue='Outlet_Type', alpha=0.6, palette='viridis')\n",
                "plt.title('Item MRP vs Outlet Sales colored by Outlet Type')\n",
                "plt.xlabel('Item MRP')\n",
                "plt.ylabel('Sales')\n",
                "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "> **Observation:** Note distinct clusters. Grocery Stores (Type 0/1?) typically stay at the bottom (low sales), while Supermarket Type 3 often dominates the upper sales spectrum for the same MRP."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Outlet Location vs Sales Distribution\n",
                "**Insight Goal:** Is the spread of sales different across Tiers?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(12, 6))\n",
                "sns.violinplot(data=df, x='Outlet_Location_Type', y='Item_Outlet_Sales', palette='muted')\n",
                "plt.title('Distribution of Sales across Location Tier')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Item Type Performance Heatmap\n",
                "**Insight Goal:** Which Item Categories perform best in which Outlet Size?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Pivot table for Heatmap\n",
                "pivot = df.pivot_table(index='Item_Type', columns='Outlet_Size', values='Item_Outlet_Sales', aggfunc='mean')\n",
                "\n",
                "plt.figure(figsize=(14, 10))\n",
                "sns.heatmap(pivot, annot=True, fmt='.0f', cmap='YlGnBu')\n",
                "plt.title('Average Sales Heatmap: Item Type vs Outlet Size')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Visibility Impact Analysis\n",
                "**Insight Goal:** Does higher visibility actually correlate with higher sales?\n",
                "We create bins for visibility to aggregate trends."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df['Visibility_Bin'] = pd.cut(df['Item_Visibility'], bins=[0, 0.05, 0.1, 0.15, 0.2, 0.35], labels=['Very Low', 'Low', 'Medium', 'High', 'Very High'])\n",
                "\n",
                "plt.figure(figsize=(10, 6))\n",
                "sns.barplot(data=df, x='Visibility_Bin', y='Item_Outlet_Sales', palette='rocket')\n",
                "plt.title('Average Sales by Visibility Level')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Fat Content vs Item Type Interaction\n",
                "**Insight Goal:** How does Fat Content affect sales within different categories (e.g., Dairy vs Meat)?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(16, 6))\n",
                "sns.boxplot(data=df, x='Item_Type', y='Item_Outlet_Sales', hue='Item_Fat_Content')\n",
                "plt.xticks(rotation=45)\n",
                "plt.title('Sales Distribution by Item Type & Fat Content')\n",
                "plt.legend(loc='upper right')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Part 2: Business Owner Insights (Readable Trends)\n",
                "We load the original dataset to use the actual Product Names and Outlet Types for easier understanding."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_raw = pd.read_csv('bigmart.csv')\n",
                "df_raw['Total_Sales'] = df_raw['Item_Outlet_Sales'] # Alias for clarity"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. What sells best where? (Year x Outlet x City)\n",
                "We group the data to find the **Top Selling Product Category** for each Store, Year, and Location."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Group by Year, Outlet Identifier, Location Type, and Item Type\n",
                "grouped = df_raw.groupby(['Outlet_Establishment_Year', 'Outlet_Identifier', 'Outlet_Location_Type', 'Item_Type'])['Total_Sales'].sum().reset_index()\n",
                "\n",
                "# Sort to find top categories\n",
                "grouped = grouped.sort_values(['Outlet_Establishment_Year', 'Outlet_Identifier', 'Total_Sales'], ascending=[True, True, False])\n",
                "\n",
                "# Get top 3 categories per store\n",
                "top_products = grouped.groupby(['Outlet_Establishment_Year', 'Outlet_Identifier']).head(3)\n",
                "\n",
                "print(\"Top 3 Selling Categories per Store over the Years:\")\n",
                "display(top_products[['Outlet_Establishment_Year', 'Outlet_Identifier', 'Outlet_Location_Type', 'Item_Type', 'Total_Sales']].style.background_gradient(cmap='Greens'))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Product Performance: Tier 1 vs Tier 3\n",
                "Do people in Tier 1 cities buy different things than Tier 3?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(14, 6))\n",
                "sns.countplot(data=df_raw, x='Item_Type', hue='Outlet_Location_Type', palette='Set2')\n",
                "plt.xticks(rotation=45, ha='right')\n",
                "plt.title('Count of Products Sold by City Tier')\n",
                "plt.legend(title='City Tier')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Part 3: API Creation for Frontend Integration\n",
                "We will create a FastAPI backend that:\n",
                "1. Loads the trained XGBoost model (`best_xgb_regressor_random_model.pkl`).\n",
                "2. Re-constructs the Label Encoders (since they weren't saved) by mapping `bigmart.csv` to `updated_dataset.csv`.\n",
                "3. Exposes a `/predict` endpoint."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%writefile backend_api.py\n",
                "import pandas as pd\n",
                "import joblib\n",
                "from fastapi import FastAPI, HTTPException\n",
                "from pydantic import BaseModel\n",
                "import uvicorn\n",
                "import os\n",
                "\n",
                "app = FastAPI(title=\"Big Mart Sales Predictor\")\n",
                "\n",
                "# --- Load Resources ---\n",
                "MODEL_PATH = \"best_xgb_regressor_random_model.pkl\"\n",
                "RAW_CSV_PATH = \"bigmart.csv\"\n",
                "ENCODED_CSV_PATH = \"updated_dataset.csv\"\n",
                "\n",
                "try:\n",
                "    model = joblib.load(MODEL_PATH)\n",
                "    print(\"Model loaded successfully.\")\n",
                "except Exception as e:\n",
                "    print(f\"Error loading model: {e}\")\n",
                "    model = None\n",
                "\n",
                "# --- Rebuild Encoders ---\n",
                "# Since we don't have the pickle files for encoders, we map Raw -> Encoded values from the datasets\n",
                "encoders = {}\n",
                "cat_cols = ['Item_Identifier', 'Item_Fat_Content', 'Item_Type', 'Outlet_Identifier', 'Outlet_Size', 'Outlet_Location_Type', 'Outlet_Type']\n",
                "\n",
                "try:\n",
                "    df_raw = pd.read_csv(RAW_CSV_PATH)\n",
                "    df_enc = pd.read_csv(ENCODED_CSV_PATH)\n",
                "    \n",
                "    # Remove duplicates to create clean mapping \n",
                "    # Ensure we sort by index to maintain row-to-row correspondence if possible\n",
                "    # Assumption: rows correspond 1-to-1\n",
                "    \n",
                "    for col in cat_cols:\n",
                "        # Create a dictionary mapping { 'RawString': EncodedInt }\n",
                "        mapping = dict(zip(df_raw[col], df_enc[col]))\n",
                "        encoders[col] = mapping\n",
                "        \n",
                "    print(\"Encoders rebuilt successfully.\")\n",
                "\n",
                "except Exception as e:\n",
                "    print(f\"Error rebuilding encoders: {e}\")\n",
                "\n",
                "class ItemPredictionRequest(BaseModel):\n",
                "    Item_Identifier: str\n",
                "    Item_Weight: float\n",
                "    Item_Fat_Content: str\n",
                "    Item_Visibility: float\n",
                "    Item_Type: str\n",
                "    Item_MRP: float\n",
                "    Outlet_Identifier: str\n",
                "    Outlet_Establishment_Year: int\n",
                "    Outlet_Size: str\n",
                "    Outlet_Location_Type: str\n",
                "    Outlet_Type: str\n",
                "\n",
                "@app.get(\"/\")\n",
                "def read_root():\n",
                "    return {\"message\": \"Big Mart Sales Prediction API is running\"}\n",
                "\n",
                "@app.post(\"/predict\")\n",
                "def predict_sales(item: ItemPredictionRequest):\n",
                "    if not model:\n",
                "        raise HTTPException(status_code=500, detail=\"Model not loaded\")\n",
                "    \n",
                "    try:\n",
                "        # Prepare input vector\n",
                "        data = item.dict()\n",
                "        \n",
                "        # Encode categorical fields using our rebuilt map\n",
                "        for col in cat_cols:\n",
                "            if col in data:\n",
                "                raw_val = data[col]\n",
                "                if raw_val not in encoders[col]:\n",
                "                     # Fallback 1: Try finding a key that contains the string (partial match)\n",
                "                     # Fallback 2: Use the most common value (mode) from encoder\n",
                "                     # Fallback 3: Default to 0 (risky but failsafe)\n",
                "                     pass\n",
                "                \n",
                "                # Apply mapping with default 0 if not found\n",
                "                data[col] = encoders[col].get(raw_val, 0)\n",
                "        \n",
                "        # Create DataFrame for model (ensure order matches training)\n",
                "        input_df = pd.DataFrame([data])\n",
                "        \n",
                "        # Order must be exact\n",
                "        required_cols = ['Item_Identifier', 'Item_Weight', 'Item_Fat_Content', 'Item_Visibility',\n",
                "                         'Item_Type', 'Item_MRP', 'Outlet_Identifier', 'Outlet_Establishment_Year',\n",
                "                         'Outlet_Size', 'Outlet_Location_Type', 'Outlet_Type']\n",
                "                         \n",
                "        input_df = input_df[required_cols]\n",
                "                             \n",
                "        prediction = model.predict(input_df)\n",
                "        return {\"predicted_sales\": float(prediction[0])}\n",
                "\n",
                "    except Exception as e:\n",
                "        raise HTTPException(status_code=400, detail=f\"Prediction error: {str(e)}\")\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    uvicorn.run(app, host=\"0.0.0.0\", port=8001)\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}