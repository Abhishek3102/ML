{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO5LleKhR9YM+flIiITGPMb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhishek3102/ML/blob/main/DogBreedClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle"
      ],
      "metadata": {
        "id": "1KxuCIS6QClC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d kabilan03/dogbreedclassification\n"
      ],
      "metadata": {
        "id": "p-2U-t9xRwGo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11f02c8a-2208-46da-fcda-2d9883b8d2cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/kabilan03/dogbreedclassification\n",
            "License(s): unknown\n",
            "Downloading dogbreedclassification.zip to /content\n",
            "100% 272M/272M [00:02<00:00, 128MB/s]\n",
            "100% 272M/272M [00:02<00:00, 97.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile('/content/dogbreedclassification.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('dataset')\n"
      ],
      "metadata": {
        "id": "juL3FAmJL8LB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import cv2\n",
        "# import numpy as np\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# from sklearn.svm import SVC\n",
        "# from sklearn.metrics import f1_score\n",
        "# import numpy as np\n",
        "# from glob import glob\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# from sklearn.svm import SVC\n",
        "# from sklearn.metrics import accuracy_score\n",
        "# import cv2\n",
        "# from skimage.feature import hog\n",
        "\n",
        "# # Function to extract HOG features from an image\n",
        "# image = cv2.imread(\"/content/dataset/Dog Breed Classification/train/bedlington_terrier/bedlington_terrier11.jpg\")\n",
        "\n",
        "# def extract_hog_features(image):\n",
        "#     features = hog.compute(image, winSize=(128, 128), blockSize=(16, 16), blockStride=(8, 8), cellSize=(8, 8),\n",
        "#                            nbins=9, winSigma=0, histogramNormType=cv2.HOGDESCRIPTOR_DEFAULT)\n",
        "#     return features.flatten()\n",
        "# # hog_features = extract_hog_features(image)\n",
        "\n",
        "# # Function to read images and extract features\n",
        "# # train_folder_path = '/content/dataset/Dog Breed Classification/train'\n",
        "# # test_folder_path = \"/content/dataset/Dog Breed Classification/test\"\n",
        "# # validity_folder_path = \"/content/dataset/Dog Breed Classification/val\"\n",
        "\n",
        "# # train_features, train_labels = read_images_and_extract_features(train_folder_path)\n",
        "# # test_features, test_labels = read_images_and_extract_features(test_folder_path)\n",
        "# # validity_features, validity_labels = read_images_and_extract_features(validity_folder_path)\n",
        "\n",
        "# folder_path = \"/content/dataset/Dog Breed Classification/train\"\n",
        "# breed_folder = \"/content/dataset/Dog Breed Classification/train/black-and-tan_coonhound\"\n",
        "\n",
        "# def read_images_and_extract_features(folder_path):\n",
        "#     features = []\n",
        "#     labels = []\n",
        "#     for label, breed in enumerate(os.listdir(folder_path)):\n",
        "#         breed_folder = os.path.join(folder_path, breed)\n",
        "#         for filename in os.listdir(breed_folder):\n",
        "#             image_path = os.path.join(breed_folder, filename)\n",
        "#             image = cv2.imread(image_path)\n",
        "#             image = cv2.resize(image, (128, 128))\n",
        "#             gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "#             hog_features = extract_hog_features(gray)\n",
        "#             features.append(hog_features)\n",
        "#             labels.append(label)\n",
        "#     return np.array(features), np.array(labels)\n",
        "\n",
        "# # Read images and extract features from train and test folders\n",
        "# train_features, train_labels = read_images_and_extract_features(\"/content/dataset/Dog Breed Classification/train\")\n",
        "# test_features, test_labels = read_images_and_extract_features(\"/content/dataset/Dog Breed Classification/test\")\n",
        "\n",
        "# # Combine train and test data\n",
        "# all_features = np.vstack((train_features, test_features))\n",
        "# all_labels = np.concatenate((train_labels, test_labels))\n",
        "\n",
        "# # Split data into training and testing sets\n",
        "# X_train, X_test, y_train, y_test = train_test_split(all_features, all_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# # Train SVM classifier\n",
        "# scaler = StandardScaler()\n",
        "# X_train_scaled = scaler.fit_transform(X_train)\n",
        "# X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# svm_classifier = SVC(kernel='linear', random_state=42)\n",
        "# svm_classifier.fit(X_train_scaled, y_train)\n",
        "\n",
        "# # Test model\n",
        "# y_pred = svm_classifier.predict(X_test_scaled)\n",
        "# f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "# print(\"F1 Score:\", f1)\n",
        "\n",
        "# # Predict breed of an image from validation folder\n",
        "# validity_features, validity_labels = read_images_and_extract_features(\"/content/dataset/Dog Breed Classification/val/airedale\")\n",
        "# validity_features_scaled = scaler.transform(validity_features)\n",
        "\n",
        "# # Take one image for prediction\n",
        "# image_path = os.path.join(\"/content/dataset/Dog Breed Classification/val\", os.listdir(\"/content/dataset/Dog Breed Classification/val\")[0])\n",
        "# image = cv2.imread(image_path)\n",
        "# image = cv2.resize(image, (128, 128))\n",
        "# gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "# hog_features = extract_hog_features(gray)\n",
        "# hog_features_scaled = scaler.transform(hog_features.reshape(1, -1))\n",
        "\n",
        "# prediction = svm_classifier.predict(hog_features_scaled)\n",
        "# print(\"Predicted breed:\", prediction[0])\n"
      ],
      "metadata": {
        "id": "K30IcFLcMyn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import f1_score\n",
        "from skimage.feature import hog as skimage_hog\n",
        "\n",
        "\n",
        "\n",
        "# Function to extract HOG features from an image\n",
        "image= cv.imread(\"/content/dataset/Dog Breed Classification/val/african_hunting_dog\")\n",
        "def extract_hog_features(image):\n",
        "    win_size = (128, 128)\n",
        "    block_size = (16, 16)\n",
        "    block_stride = (8, 8)\n",
        "    cell_size = (8, 8)\n",
        "    nbins = 9\n",
        "\n",
        "    hog = cv2.HOGDescriptor(win_size, block_size, block_stride, cell_size, nbins)\n",
        "    features = hog.compute(image)\n",
        "    return features.flatten()\n",
        "\n",
        "# Function to read images and extract features\n",
        "folder_path = \"/content/dataset/Dog Breed Classification/train\"\n",
        "breed_folder = \"/content/dataset/Dog Breed Classification/train/basenji\"\n",
        "\n",
        "def read_images_and_extract_features(folder_path):\n",
        "    features = []\n",
        "    labels = []\n",
        "    for label, breed in enumerate(os.listdir(folder_path)):\n",
        "        breed_folder = os.path.join(folder_path, breed)\n",
        "        for filename in os.listdir(breed_folder):\n",
        "            image_path = os.path.join(breed_folder, filename)\n",
        "            image = cv.imread(\"/content/dataset/Dog Breed Classification/train/basenji/basenji100.jpg\")\n",
        "            image = cv.resize(image, (128, 128))\n",
        "            gray = cv.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "            hog_features = extract_hog_features(gray)\n",
        "            features.append(hog_features)\n",
        "            labels.append(label)\n",
        "    return np.array(features), np.array(labels)\n",
        "\n",
        "# Read images and extract features from train and test folders\n",
        "train_features, train_labels = read_images_and_extract_features(\"/content/dataset/Dog Breed Classification/train\")\n",
        "test_features, test_labels = read_images_and_extract_features(\"/content/dataset/Dog Breed Classification/test\")\n",
        "\n",
        "# Combine train and test data\n",
        "all_features = np.vstack((train_features, test_features))\n",
        "all_labels = np.concatenate((train_labels, test_labels))\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(all_features, all_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train SVM classifier\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "svm_classifier = SVC(kernel='linear', random_state=42)\n",
        "svm_classifier.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Test model\n",
        "y_pred = svm_classifier.predict(X_test_scaled)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "print(\"F1 Score:\", f1)\n",
        "\n",
        "# Predict breed of an image from validation folder\n",
        "validity_features, validity_labels = read_images_and_extract_features(\"/content/dataset/Dog Breed Classification/val\")\n",
        "validity_features_scaled = scaler.transform(validity_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiQaUMN-O7rl",
        "outputId": "1d5aa55f-86e9-4101-f629-f680b2d05e0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score: 0.002193793866381412\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Take one image for prediction\n",
        "image_path = os.path.join(\"/content/dataset/Dog Breed Classification/val\", os.listdir(\"/content/dataset/Dog Breed Classification/val\")[0])\n",
        "image = cv.imread(\"/content/dataset/Dog Breed Classification/val/basset/basset16.jpg\")\n",
        "image = cv.resize(image, (128, 128))\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "hog_features = extract_hog_features(gray)\n",
        "hog_features_scaled = scaler.transform(hog_features.reshape(1, -1))\n",
        "\n",
        "prediction = svm_classifier.predict(hog_features_scaled)\n",
        "print(\"Predicted breed:\", prediction[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iv5YIsLDkcAv",
        "outputId": "01869822-d3f9-4c6b-806d-ae0f8f31cf9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted breed: 92\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import f1_score\n",
        "from skimage.feature import hog as skimage_hog\n",
        "\n",
        "# Function to extract HOG features from an image\n",
        "def extract_hog_features(image):\n",
        "    win_size = (128, 128)\n",
        "    block_size = (16, 16)\n",
        "    block_stride = (8, 8)\n",
        "    cell_size = (8, 8)\n",
        "    nbins = 9\n",
        "\n",
        "    hog = cv2.HOGDescriptor(win_size, block_size, block_stride, cell_size, nbins)\n",
        "    features = hog.compute(image)\n",
        "    return features.flatten()\n",
        "\n",
        "# Function to read images and extract features\n",
        "def read_images_and_extract_features(folder_path):\n",
        "    features = []\n",
        "    labels = []\n",
        "    breed_names = []\n",
        "    for label, breed in enumerate(os.listdir(folder_path)):\n",
        "        breed_folder = os.path.join(folder_path, breed)\n",
        "        for filename in os.listdir(breed_folder):\n",
        "            image_path = os.path.join(breed_folder, filename)\n",
        "            image = cv2.imread(image_path)\n",
        "            image = cv2.resize(image, (128, 128))\n",
        "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "            hog_features = extract_hog_features(gray)\n",
        "            features.append(hog_features)\n",
        "            labels.append(label)\n",
        "            breed_names.append(breed)  # Append breed name\n",
        "    return np.array(features), np.array(labels), breed_names\n",
        "\n",
        "# Read images and extract features from train and test folders\n",
        "train_features, train_labels, train_breed_names = read_images_and_extract_features(\"/content/dataset/Dog Breed Classification/train\")\n",
        "test_features, test_labels, test_breed_names = read_images_and_extract_features(\"/content/dataset/Dog Breed Classification/test\")\n",
        "\n",
        "# Combine train and test data\n",
        "all_features = np.vstack((train_features, test_features))\n",
        "all_labels = np.concatenate((train_labels, test_labels))\n",
        "all_breed_names = train_breed_names + test_breed_names\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test, breed_names_train, breed_names_test = train_test_split(all_features, all_labels, all_breed_names, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train SVM classifier\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "svm_classifier = SVC(kernel='linear', random_state=42)\n",
        "svm_classifier.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Test model\n",
        "y_pred = svm_classifier.predict(X_test_scaled)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "print(\"F1 Score:\", f1)\n",
        "\n",
        "# Predict breed of an image from validation folder\n",
        "validity_features, validity_labels, validity_breed_names = read_images_and_extract_features(\"/content/dataset/Dog Breed Classification/val/airedale\")\n",
        "validity_features_scaled = scaler.transform(validity_features)\n",
        "\n",
        "# Take one image for prediction\n",
        "image_path = os.path.join(\"/content/dataset/Dog Breed Classification/val/airedale\", os.listdir(\"/content/dataset/Dog Breed Classification/val/airedale\")[0])\n",
        "image = cv2.imread(image_path)\n",
        "image = cv2.resize(image, (128, 128))\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "hog_features = extract_hog_features(gray)\n",
        "hog_features_scaled = scaler.transform(hog_features.reshape(1, -1))\n",
        "\n",
        "prediction = svm_classifier.predict(hog_features_scaled)\n",
        "breed_name = validity_breed_names[0]  # Get breed name from the validity set\n",
        "print(\"Predicted breed:\", breed_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "N_D5jZ_nx5OP",
        "outputId": "cb151f8c-51ae-4287-d16d-e6ec435d6b04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/dataset/Dog Breed Classification/train'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-39284b32f5ab>\u001b[0m in \u001b[0;36m<cell line: 41>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# Read images and extract features from train and test folders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_breed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_images_and_extract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/dataset/Dog Breed Classification/train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0mtest_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_breed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_images_and_extract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/dataset/Dog Breed Classification/test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-39284b32f5ab>\u001b[0m in \u001b[0;36mread_images_and_extract_features\u001b[0;34m(folder_path)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mbreed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbreed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mbreed_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbreed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbreed_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/dataset/Dog Breed Classification/train'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aWN6rqse5mk2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}