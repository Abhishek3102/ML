{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# SHAP and LIME Analysis (Local Version)\n",
                "\n",
                "## Objective\n",
                "Analyze decisive factors for restaurant reviews using SHAP and LIME.\n",
                "This version uses **Sentence Transformers** (local execution) to generate embeddings and derive the 'Sentiment' target, avoiding API rate limits and instability.\n",
                "\n",
                "## Pipeline\n",
                "1. **Load Data**: Read `train_data.csv`.\n",
                "2. **Target Engineering (Local)**: \n",
                "    - Generate embeddings using `sentence-transformers` (Model: `all-MiniLM-L6-v2`).\n",
                "    - Calculate Cosine Similarity against positive/negative anchors.\n",
                "    - Derive `Sentiment` (0 or 1).\n",
                "3. **Modeling**: Train Random Forest (`Age`, `Gender`, `Meal_Category` -> `Sentiment`).\n",
                "4. **Explainability**: SHAP (Global/Local) and LIME (Instance-level)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install necessary libraries if not present\n",
                "# !pip install sentence-transformers shap lime qdrant-client pandas numpy scikit-learn matplotlib seaborn\n",
                "\n",
                "import os\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sentence_transformers import SentenceTransformer\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.metrics import accuracy_score, classification_report\n",
                "from sklearn.metrics.pairwise import cosine_similarity\n",
                "import shap\n",
                "import lime\n",
                "import lime.lime_tabular\n",
                "\n",
                "pd.set_option('display.max_columns', None)\n",
                "pd.set_option('display.width', 1000)\n",
                "\n",
                "print(\"Libraries loaded successfully.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pd.read_csv('train_data.csv')\n",
                "print(f\"Data Shape: {df.shape}\")\n",
                "\n",
                "# Optional: Load from backup if available to save time\n",
                "backup_file = 'train_data_with_embeddings_BACKUP.csv'\n",
                "if os.path.exists(backup_file):\n",
                "    print(f\"Found backup file '{backup_file}'. You can load this to skip generation if compatible.\")\n",
                "    # df = pd.read_csv(backup_file)\n",
                "\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Feature Engineering: Local Semantic Sentiment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize Sentence Transformer Model\n",
                "# 'all-MiniLM-L6-v2' is fast (perfect for 2k rows) and accurate enough for sentiment separation\n",
                "try:\n",
                "    print(\"Loading SentenceTransformer model...\")\n",
                "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
                "\n",
                "    # Generate Embeddings\n",
                "    print(\"Generating embeddings for all reviews...\")\n",
                "    review_embeddings = model.encode(df['review'].tolist(), show_progress_bar=True)\n",
                "    df['embedding'] = list(review_embeddings)\n",
                "\n",
                "    print(\"Embedding generation complete.\")\n",
                "except Exception as e:\n",
                "    print(f\"Error generating embeddings: {e}\")\n",
                "    print(\"Generating dummy embeddings for testing...\")\n",
                "    df['embedding'] = [np.random.rand(384) for _ in range(len(df))]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Semantic Sentiment Derivation\n",
                "try:\n",
                "    pos_text = \"Positive restaurant experience, delicious food, great service, loved it\"\n",
                "    neg_text = \"Negative restaurant experience, bad food, terrible service, not recommended\"\n",
                "\n",
                "    pos_anchor = model.encode([pos_text]) # Returns (1, 384)\n",
                "    neg_anchor = model.encode([neg_text])\n",
                "\n",
                "    def derive_sentiment(row_embedding, pos_anchor, neg_anchor):\n",
                "        # Reshape for sklearn cosine_similarity (1, -1)\n",
                "        emb = row_embedding.reshape(1, -1)\n",
                "        \n",
                "        pos_sim = cosine_similarity(emb, pos_anchor)[0][0]\n",
                "        neg_sim = cosine_similarity(emb, neg_anchor)[0][0]\n",
                "        \n",
                "        return 1 if pos_sim > neg_sim else 0\n",
                "\n",
                "    df['Sentiment'] = df['embedding'].apply(lambda x: derive_sentiment(x, pos_anchor, neg_anchor))\n",
                "\n",
                "    print(\"Sentiment Distribution:\")\n",
                "    print(df['Sentiment'].value_counts())\n",
                "except Exception as e:\n",
                "    print(f\"Error processing sentiment: {e}\")\n",
                "    df['Sentiment'] = np.random.randint(0, 2, size=len(df))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Modeling: Random Forest\n",
                "Predicting the semantically derived `Sentiment` using `Age`, `Gender`, and `Meal_Category`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Preprocessing\n",
                "le_gender = LabelEncoder()\n",
                "le_meal = LabelEncoder()\n",
                "\n",
                "df['Gender_Code'] = le_gender.fit_transform(df['gender'])\n",
                "df['Meal_Code'] = le_meal.fit_transform(df['meal_category'])\n",
                "\n",
                "X = df[['age', 'Gender_Code', 'Meal_Code']]\n",
                "y = df['Sentiment']\n",
                "\n",
                "# Train/Test Split\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "\n",
                "# Model Training\n",
                "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
                "clf.fit(X_train, y_train)\n",
                "\n",
                "# Evaluation\n",
                "y_pred = clf.predict(X_test)\n",
                "print(\"Classification Report:\")\n",
                "print(classification_report(y_test, y_pred))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Advanced SHAP Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Explain feature importance using the modern SHAP API\n",
                "# Creating a generic Explainer for cleaner API usage\n",
                "explainer = shap.Explainer(clf, X_train)\n",
                "# shap_values_obj will be an Explanation object containing .values, .base_values, .data\n",
                "shap_values_obj = explainer(X_test)\n",
                "\n",
                "# For binary classification, shap_values_obj has structure (n_samples, n_features, n_classes)\n",
                "# We focus on the positive class (index 1) which represents Sentiment=1\n",
                "# Slicing acts on the Explanation object itself\n",
                "vals = shap_values_obj[..., 1]\n",
                "\n",
                "print(\"--- 5. Advanced SHAP Analysis ---\")\n",
                "\n",
                "# 1. Beeswarm Plot (Upgrade from Summary Plot)\n",
                "# Shows distribution of Shapley values for each feature\n",
                "plt.figure()\n",
                "plt.title(\"SHAP Beeswarm Plot (Global Feature Importance)\")\n",
                "shap.plots.beeswarm(vals, show=True)\n",
                "\n",
                "# 2. Bar Plot (Absolute Mean Importance)\n",
                "plt.figure()\n",
                "plt.title(\"SHAP Bar Plot (Mean Absolute Impact)\")\n",
                "shap.plots.bar(vals, show=True)\n",
                "\n",
                "# 3. Waterfall Plot (Local Instance Explanation)\n",
                "# Explains how each feature contributed to moving the prediction from the base value to the final score\n",
                "instance_idx = 0\n",
                "print(f\"\\nWaterfall for instance {instance_idx}:\")\n",
                "plt.figure()\n",
                "plt.title(f\"SHAP Waterfall Plot for Instance {instance_idx}\")\n",
                "shap.plots.waterfall(vals[instance_idx], show=True)\n",
                "\n",
                "# 4. Heatmap Plot (Instance Clustering)\n",
                "# Shows patterns of explanation similarity across samples\n",
                "plt.figure()\n",
                "plt.title(\"SHAP Heatmap (Top 100 Samples)\")\n",
                "shap.plots.heatmap(vals[:100], show=True)\n",
                "\n",
                "# 5. Dependence Plot (Feature Interactions)\n",
                "# Shows how \"Age\" effect varies, colored by \"Meal_Code\" interaction\n",
                "# Note: dependence_plot uses raw matplotlib/legacy API, so we pass .values and raw X matrix\n",
                "plt.figure()\n",
                "shap.dependence_plot(\"age\", vals.values, X_test, interaction_index=\"Meal_Code\", show=False)\n",
                "plt.title(\"SHAP Dependence Plot: Age vs Imapct (Color by Meal)\")\n",
                "plt.show()\n",
                "\n",
                "# 6. Decision Plot (Prediction Path)\n",
                "# Visualizes the cumulative effect of features for a group of samples\n",
                "plt.figure()\n",
                "plt.title(\"SHAP Decision Plot (First 20 paths)\")\n",
                "# Need base value (expected value) for the positive class\n",
                "expected_value = explainer.expected_value[1]\n",
                "shap.decision_plot(expected_value, vals.values[:20], X_test.iloc[:20], show=True)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Advanced LIME Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Using SP-LIME (Submodular Pick) to find representative instances\n",
                "# This selects a diverse set of instances that cover important feature behaviors\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore') # Suppress LIME warnings\n",
                "\n",
                "lime_explainer = lime.lime_tabular.LimeTabularExplainer(\n",
                "    training_data=np.array(X_train),\n",
                "    feature_names=['Age', 'Gender', 'Meal_Category'],\n",
                "    class_names=['Negative', 'Positive'],\n",
                "    mode='classification',\n",
                "    discretize_continuous=True\n",
                ")\n",
                "\n",
                "# Explain one instance with detailed visualization\n",
                "exp = lime_explainer.explain_instance(\n",
                "    data_row=X_test.iloc[0].values, \n",
                "    predict_fn=clf.predict_proba, \n",
                "    num_features=5\n",
                ")\n",
                "print(\"LIME Explanation for Instance 0 (List):\")\n",
                "print(exp.as_list())\n",
                "# In a real notebook, exp.show_in_notebook() creates an HTML visualization\n",
                "exp.show_in_notebook(show_table=True, show_all=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}